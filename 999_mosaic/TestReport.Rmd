---
title: "Analysis Report"
author: "LAN"
date: "`r Sys.Date()`"
output:
  html_document:
    self_contained: true  # Set to true if you want a standalone HTML file
    output_file: "/report.html"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Install required packages if not already installed
if (!require("tidyverse")) {
  install.packages("tidyverse")
}
if (!require("car")) {
  install.packages("car")
}
if (!require("multcomp")) {
  install.packages("multcomp")
}

if (!require("irr")) {
  install.packages("irr")
}

if (!require("stats")) {
  install.packages("stats")
}

# Load necessary libraries
library(tidyverse)
library(car)  # For ANOVA
library(multcomp)  # For post-hoc tests
library(irr) # For ICC
library(stats)  # For Kolmogorov-Smirnov test
```

# Summary Statistics

- Summary Statistics: Mean (average value), SD (standard deviation), Median (middle value), IQR (interquartile range). These statistics provide insights into the central tendency and variability of counts across different methods and severity levels.

- Given the differences in how the methods aggregate PiN at Admin2, a statistically sound approach would be to use a summary statistic that captures the central tendency and variability appropriately. Instead of focusing solely on the mean or sum, a combination of median and interquartile range (IQR) can provide a more robust measure that is less affected by outliers and more comparable across different methods.

- High variability (SD) indicates fluctuating estimates.
- Lower variability (SD) suggests a more consistent estimates.

```{r summary_stats, echo=FALSE, message=FALSE}
# Read the CSV file
method4 <- read.csv("process/4.modified_data_highest_sector_pin.csv")
method5 <- read.csv("process/5.OverallSeverityDistributionMosaic.csv")
method6 <- read.csv("process/6.AverageAndMedianSeverityDistributionMosaic.csv")

# View the data structure

#cat("Structure of the data frame:\n")
#cat("Data based on Method 4 - Maximum Sector PiN distribution")
#str(method4)
#cat("Data based on Method 5 - mosaic method stop at level3")
#str(method5)
#cat("Data based on Method 6 - Mean/Median stop at level3 (Level 3 is residual)")
#str(method6)

# Standardize method5 and method6 and method4's structure
method5_long <- method5 %>%
  dplyr::select(Admin.2.Pcode, dummy_pin_5_max, dummy_pin_4_max, dummy_pin_3_max) %>%
  pivot_longer(cols = starts_with("dummy_pin_"), names_to = "Severity", values_to = "Count") %>%
  mutate(Method = "method5", Severity = as.integer(str_extract(Severity, "\\d")))

method6_avg_long <- method6 %>%
  dplyr::select(Admin.2.Pcode, dummy_pin_5_avg, dummy_pin_4_avg, dummy_pin_3_avg) %>%
  pivot_longer(cols = starts_with("dummy_pin_"), names_to = "Severity", values_to = "Count") %>%
  mutate(Method = "method6_avg", Severity = as.integer(str_extract(Severity, "\\d")))

method6_median_long <- method6 %>%
  dplyr::select(Admin.2.Pcode, dummy_pin_5_median, dummy_pin_4_median, dummy_pin_3_median) %>%
  pivot_longer(cols = starts_with("dummy_pin_"), names_to = "Severity", values_to = "Count") %>%
  mutate(Method = "method6_median", Severity = as.integer(str_extract(Severity, "\\d")))

method4_long <- method4 %>%
  dplyr::select(Admin.2.Pcode, dummy_pin_3, dummy_pin_4, dummy_pin_5) %>%
  pivot_longer(cols = starts_with("dummy_pin_"), names_to = "Severity", values_to = "Count") %>%
  mutate(Method = "method4", Severity = as.integer(str_extract(Severity, "\\d")))

# Combine all methods into a single dataframe
combined_data <- bind_rows(method4_long, method5_long, method6_avg_long, method6_median_long)

# View combined data
#head(combined_data)

# Test 1: Summary statistics by method and severity
stats <- combined_data %>%
  group_by(Method) %>%
  summarise(SD = sd(Count, na.rm = TRUE), Median = median(Count, na.rm = TRUE), SumPiN = formatC(sum(Count, na.rm = TRUE), format = "f", big.mark = ","), IQR = IQR(Count, na.rm = TRUE), .groups = 'keep')

print(stats)

# Test 1: Summary statistics by method and severity
summary_stats <- combined_data %>%
  group_by(Method, Severity) %>%
  summarise(Mean = mean(Count, na.rm = TRUE), SD = sd(Count, na.rm = TRUE), Median = median(Count, na.rm = TRUE), Sum = formatC(sum(Count, na.rm = TRUE), format = "f", big.mark = ","), IQR = IQR(Count, na.rm = TRUE), .groups = 'keep')

print(summary_stats)

```

# Test 2: Visulization

## Visualizations

  - Boxplot: 
    - The boxplot visualizes the distribution of the population in need (PiN) at the Admin2 level for each severity level and each method (Method 4, Method 5, Method 6_avg, Method 6_median). 
    - Each boxplot displays the median, interquartile range (IQR), and potential outliers. The median represents the central value of the distribution, while the IQR shows the spread of the middle 50% of the data. This approach highlights the distribution and variability within each method.
  - Density Plot: Illustrates the distribution of PiN across methods for each severity level.
  

```{r visulization, echo=FALSE}
# Calculate the PiN in Admin2 in each Severity level - 3 Methods
sum_data <- combined_data %>%
  group_by(Severity, Method) %>%
  summarise(Sum = sum(Count), .groups = "drop")
# head(sum_data)

# Create a bar chart
ggplot(sum_data, aes(x = Severity, y = Sum/ 1000000, fill = Method)) +
  geom_bar(stat = "identity", position = "dodge") +
  #facet_grid(~ Severity) +
  labs(
    title = "Total PiN in Admin2 by Severity Level and Method",
    x = "Severity Level",
    y = "Total PiN in [Millions]",
    fill = "Method"
  ) +
  scale_fill_discrete(labels = c("Method 4", "Method 5", "Method 6_avg", "Method 6_median")) +
 theme(strip.background = element_rect(colour="grey", fill="grey", 
                                       linewidth=1.5, linetype="solid"))
# Boxplot
ggplot(combined_data, aes(x = as.factor(Severity), y = Count, fill = Method)) +
  geom_boxplot() +
  labs(title = "Distribution of Counts by Method and Severity Level", x = "Severity Level", y = "Count")

# Create a scatter plot
ggplot(combined_data, aes(x = Admin.2.Pcode, y = Count, color = Severity)) +
  geom_point() +
  facet_grid(~ Method) +
  labs(x = "Admin2", y = "PiN", color = "Severity") +
  scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "RdYlBu"))) +
  theme(strip.background = element_rect(colour="grey", fill="grey", 
                                       linewidth=1.5, linetype="solid"))

# Density plot
ggplot(combined_data, aes(x = Count, fill = Method)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Severity) +
  labs(title = "Density Plot of Counts by Method and Severity Level", x = "PiN", y = "Density")
```

# Test 3: ANOVA Test

## ANOVA Results:

- ANOVA: Method tests for significant differences between method.
- Severity examines differences across severity levels.
- Method:Severity tests for interaction effect. 
- Residuals represent unexplained variation.

```{r anova, echo=FALSE}
# Test 2:  Perform ANOVA
anova_result <- aov(Count ~ Method * Severity, data = combined_data)
summary(anova_result)

# Interaction Plot
interaction.plot(combined_data$Severity, combined_data$Method, combined_data$Count,
                 main = "Interaction Plot: Method and Severity Level",
                 xlab = "Severity Level",
                 ylab = "Count",
                 legend = TRUE)

```


# Test 4: Goodness-of-fit test (Chi-squared test)

## Goodness-of-Fit (Chi-squared)


```{r chi, echo=FALSE}
# Calculate expected frequencies based on overall mean
expected_counts <- combined_data %>%
  group_by(Severity) %>%
  summarise(Expected = mean(Count, na.rm = TRUE))

# Join with the combined data
combined_data <- combined_data %>%
  left_join(expected_counts, by = "Severity")

# Calculate chi-squared goodness-of-fit for each method and severity
gof_results <- combined_data %>%
  group_by(Method, Severity) %>%
  summarise(Observed = sum(Count, na.rm = TRUE),
            Expected = sum(Expected, na.rm = TRUE)) %>%
  mutate(ChiSq = (Observed - Expected)^2 / Expected) %>%
  summarise(ChiSq = sum(ChiSq))

print(gof_results)
```

# Test 5: Perform Kolmogorov-Smirnov test between methods

## Kolmogorov-Smirnov Test

- Kolmogorov-Smirnov Test: P-values indicate whether distributions between methods are significantly different. Lower values suggest significant differences.

```{r kolo, echo=FALSE}
ks_results <- list()

methods <- unique(combined_data$Method)

for (i in 1:(length(methods) - 1)) {
  for (j in (i + 1):length(methods)) {
    method1 <- combined_data %>% filter(Method == methods[i]) %>% pull(Count)
    method2 <- combined_data %>% filter(Method == methods[j]) %>% pull(Count)
    ks_test <- ks.test(method1, method2)
    ks_results[[paste(methods[i], methods[j], sep = "_vs_")]] <- ks_test$p.value
  }
}

# Print Kolmogorov-Smirnov test results
ks_results
```


# Test 6: Intraclass correlation coefficient (ICC)

## Intraclass Correlation Coefficient (ICC)

- Intraclass Correlation Coefficient (ICC): ICC values assess consistency among methods. Higher values (>0.75) indicate better agreement.

```{r icc, echo=FALSE}
# Test 6: Convert combined data to wide format for ICC calculation
combined_wide <- combined_data %>%
  pivot_wider(names_from = Method, values_from = Count) %>%
  dplyr::select(-c(Admin.2.Pcode, Severity))

# Intraclass correlation coefficient (ICC)
icc_result <- icc(combined_wide, model = "twoway", type = "consistency", unit = "average")
print(icc_result)
```

# Overall Conclusion

**Ultimately, the choice of the most appropriate method depends on the experts opinion and the context and criteria such as fit, consistency, and count levels**
